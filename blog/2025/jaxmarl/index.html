<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Testing the new JaxMARL library | Dr. Mario Hevia Fajardo</title> <meta name="author" content="Mario A. Hevia Fajardo"> <meta name="description" content="Testing JaxMARL, a cutting-edge library for multi-agent reinforcement learning, built on the high-performance JAX framework for efficient parallel computation."> <meta name="keywords" content="evolutionary-computation, evolutionary-algorithms, runtime-analysis, research, theory"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/icon.png"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://mariohevia.github.io/blog/2025/jaxmarl/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">{
      "title": "Testing the new JaxMARL library",
      "description": "Testing JaxMARL, a cutting-edge library for multi-agent reinforcement learning, built on the high-performance JAX framework for efficient parallel computation.",
      "published": "January 15, 2025",
      "authors": [
        {
          "author": "Mario A. Hevia Fajardo",
          "authorURL": "https://mhevia.com",
          "affiliations": [
            {
              "name": "University of Birmingham",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Dr. Mario Hevia Fajardo</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right font-weight-bold" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Home</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Testing the new JaxMARL library</h1> <p>Testing JaxMARL, a cutting-edge library for multi-agent reinforcement learning, built on the high-performance JAX framework for efficient parallel computation.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#introduction">Introduction</a></div> <div><a href="#installation">Installation</a></div> <div><a href="#running-a-baseline-algorithm">Running a Baseline Algorithm</a></div> <div><a href="#conclusions">Conclusions</a></div> </nav> </d-contents> <h1 id="introduction">Introduction</h1> <p>In this blog post, I’ll share my experience getting started with JaxMARL, a new library presented in <a href="https://neurips.cc/virtual/2024/poster/97649" rel="external nofollow noopener" target="_blank">NeurIPS 2024</a>. It is designed for multi-agent reinforcement learning using JAX. JaxMARL promises ‘ease-of-use with GPU-enabled efficiency’ with support of a wide range of commonly used MARL environments like Multi-Agent Particle Environment (MPE) and some baseline algorithms.</p> <p>I’ll walk you through how I installed JaxMARL, dealt with some installation hiccups, and got everything running smoothly. By the end, I’ll check one of the baseline algorithms from the library to familiarise myself with it and see how it performs.</p> <h1 id="installation">Installation</h1> <p>The easiest way to install a new Python library is often to create a fresh environment and use Python’s package manager, <code>pip</code>. So naturally, the first thing I did was run <code>pip install jaxmarl</code>.</p> <p>Everything seemed to install smoothly. But when I tried <code class="language-python">import jaxmarl</code> I got the following error:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>AttributeError: <span class="s1">'Config'</span> object has no attribute <span class="s1">'define_bool_state'</span>
</code></pre></div></div> <p>This turned out to be a version mismatch between <code>jax</code>, <code>flax</code>, and <code>jaxMARL</code>. Despite my best efforts to manually match the library versions, I couldn’t get it to work. After checking the <a href="https://github.com/FLAIROx/JaxMARL/issues" rel="external nofollow noopener" target="_blank">Github issues page</a>, I realized I wasn’t alone; others had faced the same issue. The suggested fix? Use the Dockerfile provided in the repository.</p> <p>Following the <a href="https://github.com/FLAIROx/JaxMARL?tab=readme-ov-file#install" rel="external nofollow noopener" target="_blank">JaxMARL installation guide</a>, I cloned the repository and set up the Docker container with these commands:</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone git@github.com:FLAIROx/JaxMARL.git
<span class="nb">cd </span>JaxMARL
make build
make run
</code></pre></div></div> <p>Once everything was set up, it was time to test if everything was working as expected. Since I’m interested in using MPE environments, I ran the script <code>mpe_introduction.py</code> from <code style="white-space: nowrap;">/jaxmarl/tutorials</code>.</p> <p>This script runs the <code>'MPE_simple_reference_v3'</code> environment from the MPE suite, randomly selecting actions for each player. In order to save the resulting animation as a GIF, I updated the last part of the script like this:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Original line:
# viz.animate(view=True)
</span>
<span class="c1"># Modified code to save the animation
</span><span class="kn">import</span> <span class="n">matplotlib.animation</span> <span class="k">as</span> <span class="n">animation</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">ani</span> <span class="o">=</span> <span class="n">animation</span><span class="p">.</span><span class="nc">FuncAnimation</span><span class="p">(</span>
    <span class="n">viz</span><span class="p">.</span><span class="n">fig</span><span class="p">,</span>
    <span class="n">viz</span><span class="p">.</span><span class="n">update</span><span class="p">,</span>
    <span class="n">frames</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">viz</span><span class="p">.</span><span class="n">state_seq</span><span class="p">),</span>
    <span class="n">blit</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
    <span class="n">interval</span> <span class="o">=</span> <span class="n">viz</span><span class="p">.</span><span class="n">interval</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ani</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sh">'</span><span class="s">animation.gif</span><span class="sh">'</span><span class="p">,</span> <span class="n">writer</span><span class="o">=</span><span class="sh">'</span><span class="s">pillow</span><span class="sh">'</span><span class="p">,</span> <span class="n">fps</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div></div> <p>And here’s the resulting animation, confirming that everything is working as intended:</p> <p style="text-align:center"><img src="../../../assets/img/blog_images/animation.gif" alt="First run of MPE using JaxMARL"></p> <h1 id="running-a-baseline-algorithm">Running a Baseline Algorithm</h1> <p>The library offers some baseline algorithms already implemented on several of its environments. Again, since I am particularly interested in the environments from MPE, I tried Independent Proximal Policy Optimisation (IPPO) on the <a href="https://pettingzoo.farama.org/environments/mpe/simple_reference" rel="external nofollow noopener" target="_blank">simple reference environment from MPE</a>. The implementation provided by JaxMARL is pretty fast, and when run, it generates a nice plot of the average returns of the players after each game, demonstrating that the algorithm is learning.</p> <p><img src="../../../assets/img/blog_images/ippo_ff_MPE_simple_spread_v3.png" alt="Training of IPPO on Simple Reference"></p> <p>However, I didn’t want to just see a plot; I wanted to observe how the algorithm’s behaviour evolved throughout the training. To achieve this, I needed to extract the information of the games played by the algorithm, which turned out to be no easy feat. The first thing to understand is that implementation uses <code class="language-python">jax.vmap</code> to parallelise several environements and random seeds, and <code class="language-python">jax.lax.scan</code> to efficiently loop through each game played and iteration of the algorithm. These functions can return data collected during the runs, but the data is returned in a stacked form. Therefore, I not only had to extract the environment states but also unstack after the training was finished.</p> <p>After doing all this, I encountered some small bugs that I initially thought were my own fault. After some debugging, I realised that I haven’t introduced any bug-the bugs were there all along! So, I reported them to the <a href="https://github.com/FLAIROx/JaxMARL/issues" rel="external nofollow noopener" target="_blank">Github issues page</a> of JaxMARL. While I don’t think the bugs significantly impacted the algorithm’s training, they did interfere with the visualisations I wanted to create. After dealing with these bugs, I was able to create a visualisation of both the first game played during training and the last one.</p> <h3 style="text-align:center" id="run-before-training">Run before training</h3> <p style="text-align:center"><img src="../../../assets/img/blog_images/animation_start.gif" alt="Run before training"></p> <h3 style="text-align:center" id="run-after-training">Run after training</h3> <p style="text-align:center"><img src="../../../assets/img/blog_images/animation_final.gif" alt="Run after training"></p> <p>We can see that the algorithm has indeed learnt something, but it is still far from perfect. The aim of the game is for the agents (green) to learn to cover all the landmarks (black) while avoiding collisions. In this case, one of the agents runs away, while the others attempt to cover (stay as close as possible to) the three landmarks on their own.</p> <h1 id="conclusions">Conclusions</h1> <p>After using and familiarising myself with JaxMARL, I believe it holds significant promise, although it still feels somewhat rough in the edges. The library’s ease of use and GPU-enabled efficiency are notable strengths, but there is room for further refinement. Despite these limitations, I plan to incorporate JaxMARL into a future project involving coevolutionary algorithms, which I’ll be showcasing on this blog. I hope to see the library evolve further in the coming updates and I will keep reporting any pesky bugs that I encounter.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2026 Mario A. Hevia Fajardo. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: February 03, 2026. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>