---
---

@article{hevia_fajardo_self-adjusting_2023,
	title = {Self-adjusting {Population} {Sizes} for {Non}-elitist {Evolutionary} {Algorithms}: {Why} {Success} {Rates} {Matter}},
	issn = {1432-0541},
	shorttitle = {Self-adjusting {Population} {Sizes} for {Non}-elitist {Evolutionary} {Algorithms}},
	url = {https://doi.org/10.1007/s00453-023-01153-9},
	doi = {10.1007/s00453-023-01153-9},
	abstract = {Evolutionary algorithms (EAs) are general-purpose optimisers that come with several 
    parameters like the sizes of parent and offspring populations or the mutation rate. It is well 
    known that the performance of EAs may depend drastically on these parameters. Recent theoretical 
    studies have shown that self-adjusting parameter control mechanisms that tune parameters during 
    the algorithm run can provably outperform the best static parameters in EAs on discrete problems. 
    However, the majority of these studies concerned elitist EAs and we do not have a clear answer on 
    whether the same mechanisms can be applied for non-elitist EAs. We study one of the best-known 
    parameter control mechanisms, the one-fifth success rule, to control the offspring population 
    size λ in the non-elitist (1,λ) EA. It is known that the (1,λ) EA has a sharp threshold with 
    respect to the choice of λ where the expected runtime on the benchmark function OneMax changes 
    from polynomial to exponential time. Hence, it is not clear whether parameter control mechanisms 
    are able to find and maintain suitable values of λ. For OneMax we show that the answer crucially 
    depends on the success rate s (i. e. a one-(s+1)-th success rule). We prove that, if the success 
    rate is appropriately small, the self-adjusting (1,λ) EA optimises OneMax in O(n) expected 
    generations and O(n log n) expected evaluations, the best possible runtime for any unary unbiased 
    black-box algorithm. A small success rate is crucial: we also show that if the success rate is too 
    large, the algorithm has an exponential runtime on OneMax and other functions with similar 
    characteristics.},
	language = {en},
	urldate = {2023-07-25},
	journal = {Algorithmica},
	author = {Hevia Fajardo, Mario Alejandro and Sudholt, Dirk},
	month = {jul},
	year = {2023},
	keywords = {Evolutionary algorithms, Non-elitism, Parameter control, Runtime analysis, Theory},
    abbr={ALGOEJ},
    selected={true},
    bibtex_show = {true},
    is_book = {false},
    is_journal = {true},
    is_conference = {false},
    pdf = {journal_saocl.pdf},
    html = {https://doi.org/10.1007/s00453-023-01153-9},
}

@article{10.1145/3564755,
author = {Hevia Fajardo, Mario Alejandro and Sudholt, Dirk},
title = {Theoretical and Empirical Analysis of Parameter Control Mechanisms in the (1 +(λ,λ)) Genetic Algorithm},
year = {2023},
issue_date = {December 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {2688-299X},
url = {https://doi.org/10.1145/3564755},
doi = {10.1145/3564755},
abstract = {The self-adjusting (1 + (λ, λ)) GA is the best known genetic algorithm for problems with a good 
fitness-distance correlation as in OneMax. It uses a parameter control mechanism for the parameter λ that 
governs the mutation strength and the number of offspring. However, on multimodal problems, the parameter 
control mechanism tends to increase λ uncontrollably. <br>
We study this problem for the standard Jump<sub>k</sub> benchmark problem class using runtime analysis. 
The self-adjusting (1 + (λ, λ)) GA behaves like a (1 +  n) EA whenever the maximum value for λ is reached. 
This is ineffective for problems where large jumps are required. Capping λ at smaller values is beneficial 
for such problems. Finally, resetting λ to 1 allows the parameter to cycle through the parameter space. 
We show that resets are effective for all Jump<sub>k</sub> problems: the self-adjusting (1 + (λ, λ)) GA 
performs as well as the (1 + 1) EA with the optimal mutation rate and evolutionary algorithms with 
heavy-tailed mutation, apart from a small polynomial overhead. <br>
Along the way, we present new general methods for translating existing runtime bounds from the (1 + 1) EA 
to the self-adjusting (1 + (λ, λ)) GA. We also show that the algorithm presents a bimodal parameter 
landscape with respect to λ on Jump<sub>k</sub>. For appropriate n and k, the landscape features a local 
optimum in a wide basin of attraction and a global optimum in a narrow basin of attraction. To our 
knowledge this is the first proof of a bimodal parameter landscape for the runtime of an evolutionary 
algorithm on a multimodal problem.},
journal = {ACM Trans. Evol. Learn. Optim.},
month = {jan},
articleno = {13},
numpages = {39},
keywords = {parameter landscape, Parameter control, theory, runtime analysis, evolutionary algorithms},
abbr={TELO},
selected={true},
bibtex_show = {true},
is_book = {false},
is_journal = {true},
is_conference = {false},
pdf = {journal_oplclga.pdf},
html = {https://doi.org/10.1145/3564755},
}